# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WQcETYD_H30o88G4wj0NqTsO2sGB14P9
"""

!pip install --ignore-installed -q pyspark==3.2.1

import os
import sys
import requests
from operator import add

from pyspark import SparkConf,SparkContext
from pyspark.streaming import StreamingContext

from pyspark.sql import SparkSession
from pyspark.sql import SQLContext

from pyspark.sql.types import *
from pyspark.sql import functions as func
from pyspark.sql.functions import *


from pyspark.ml import Pipeline
from pyspark.ml.clustering import GaussianMixture, KMeans
from pyspark.ml.feature import VectorAssembler, OneHotEncoder, StringIndexer
from pyspark.ml.evaluation import ClusteringEvaluator, MulticlassClassificationEvaluator
from pyspark.ml.classification import LogisticRegression, RandomForestClassifier
from pyspark.mllib.evaluation import MulticlassMetrics
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

spark = SparkSession.builder \
    .appName("Airport GMM") \
    .getOrCreate()

# entry info:
# Airport ID,Name,City,Country,IATA,ICAO,Latitude,Longitude,Altitude,
# Timezone,DST,Tz database,time zone Type, Source
schema = StructType([
    StructField("AirportID", IntegerType(), True),
    StructField("Name", StringType(), True),
    StructField("City", StringType(), True),
    StructField("Country", StringType(), True),
    StructField("IATA", StringType(), True),
    StructField("ICAO", StringType(), True),
    StructField("Latitude", DoubleType(), True),
    StructField("Longitude", DoubleType(), True),
    StructField("Altitude", IntegerType(), True),
    StructField("Timezone", DoubleType(), True),
    StructField("DST", StringType(), True),
    StructField("TzDatabase", StringType(), True),
    StructField("Type", StringType(), True),
    StructField("Source", StringType(), True)
])

df = spark.read.csv("rawdata.txt", sep=",", header=False, schema=schema)

# assign label to numbers for classification
df = df.withColumn("label",
                   when(df["Type"] == "airport", 1)
                   .when(df["Type"] == "station", 2)
                   .when(df["Type"] == "port", 3)
                   .when(df["Type"] == "unknown", 4))
df.show(5)
print(df.count())
len(df.columns)
# choosing entries for clustering:
# Latitude,Longitude,Altitude,Timezone,DST

print("Number of null values in 'label' column:", df.filter(df["label"].isNull()).count())

#cleaning steps
df = df.dropna(subset=["Latitude", "Longitude", "Altitude", "Timezone","label"])
print(df.count())

vec_assembler = VectorAssembler(inputCols=["Timezone"], outputCol="features")

# set models
# I used 3 here by elbow method and it shows 3 is good for both of them
gmm = GaussianMixture(k=3, tol=0.0001, seed=10)
kmeans = KMeans(k=3, tol=0.0001, seed=10)

# build pipelines
pipeline_gmm = Pipeline(stages=[vec_assembler, gmm])
pipeline_kmeans = Pipeline(stages=[vec_assembler, kmeans])

# spliting the data into train and test
train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)

# fit models and make prediction
model_kmeans = pipeline_kmeans.fit(train_data)
model_gmm = pipeline_gmm.fit(train_data)

predictions_kmeans_train = model_kmeans.transform(train_data)
predictions_kmeans_test = model_kmeans.transform(test_data)

predictions_gmm_train = model_gmm.transform(train_data)
predictions_gmm_test = model_gmm.transform(test_data)

# lld for gmm

gmm_summary = model_gmm.stages[-1].summary
lld_gmm = gmm_summary.logLikelihood

print(f"Log-Likelihood of the GMM: {lld_gmm}")

# since kmeans does not have lld, I use silhouette to meaure both of them
evaluator = ClusteringEvaluator()

# Evaluate K-Means
silhouette_kmeans_train = evaluator.evaluate(predictions_kmeans_train)
silhouette_kmeans_test = evaluator.evaluate(predictions_kmeans_test)

# Evaluate GMM
silhouette_gmm_train = evaluator.evaluate(predictions_gmm_train)
silhouette_gmm_test = evaluator.evaluate(predictions_gmm_test)

print(f"K-Means Silhouette Score (Train): {silhouette_kmeans_train}, (Test): {silhouette_kmeans_test}")
print(f"GMM Silhouette Score (Train): {silhouette_gmm_train}, (Test): {silhouette_gmm_test}")

summary_stats_gmm = predictions_gmm_test.groupBy("prediction").agg(
    func.min("Timezone").alias("Min Timezone"),
    func.max("Timezone").alias("Max Timezone"),
    func.mean("Timezone").alias("Mean Timezone"),
    func.stddev("Timezone").alias("StdDev Timezone")
).orderBy("prediction")

summary_stats_gmm.show()

# both models provide high score and test scores are very close to the training score,
# which indicating model generalizes well

# K-Means has a slightly higher score in both training and testing,
# which suggesting it might be a better fit

# Convert to Pandas DataFrame for plotting
# Used Latitude and Longitude for plotting to make the image simialr to a real map
predictions_kmeans_pd = predictions_kmeans_test.select("Latitude", "Longitude", "prediction").toPandas()
predictions_gmm_pd = predictions_gmm_test.select("Latitude", "Longitude", "prediction").toPandas()


# Plot Kmeans
for cluster_id in predictions_kmeans_pd['prediction'].unique():
    subset = predictions_kmeans_pd[predictions_kmeans_pd['prediction'] == cluster_id]
    plt.scatter(subset['Longitude'], subset['Latitude'], label=f'Cluster {cluster_id}')

plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.title("Kmeans Clustering Based on Timezone")
plt.legend(title='Cluster ID')
plt.show()

# Plot GMM
for cluster_id in predictions_gmm_pd['prediction'].unique():
    subset = predictions_gmm_pd[predictions_gmm_pd['prediction'] == cluster_id]
    plt.scatter(subset['Longitude'], subset['Latitude'], label=f'Cluster {cluster_id}')

plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.title("GMM Clustering Based on Timezone")
plt.legend(title='Cluster ID')
plt.show()

# use Altitude for clustering
gmm = GaussianMixture(k=3, tol=0.0001, seed=10)
kmeans = KMeans(k=3, tol=0.0001, seed=10)

feature_columns = ["Altitude"]
vec_assembler2 = VectorAssembler(inputCols=feature_columns, outputCol="features")

pipeline_gmm = Pipeline(stages=[vec_assembler2, gmm])
pipeline_kmeans = Pipeline(stages=[vec_assembler2, kmeans])

model_kmeans = pipeline_kmeans.fit(train_data)
model_gmm = pipeline_gmm.fit(train_data)

predictions_kmeans_train = model_kmeans.transform(train_data)
predictions_kmeans_test = model_kmeans.transform(test_data)

predictions_gmm_train = model_gmm.transform(train_data)
predictions_gmm_test = model_gmm.transform(test_data)

evaluator = ClusteringEvaluator()

# Evaluate K-Means
silhouette_kmeans_train = evaluator.evaluate(predictions_kmeans_train)
silhouette_kmeans_test = evaluator.evaluate(predictions_kmeans_test)

# Evaluate GMM
silhouette_gmm_train = evaluator.evaluate(predictions_gmm_train)
silhouette_gmm_test = evaluator.evaluate(predictions_gmm_test)

print(f"K-Means Silhouette Score (Train): {silhouette_kmeans_train}, (Test): {silhouette_kmeans_test}")
print(f"GMM Silhouette Score (Train): {silhouette_gmm_train}, (Test): {silhouette_gmm_test}")

summary_stats_gmm = predictions_gmm_test.groupBy("prediction").agg(
    func.min("Altitude").alias("Min Altitude"),
    func.max("Altitude").alias("Max Altitude"),
    func.mean("Altitude").alias("Mean Altitude"),
    func.stddev("Altitude").alias("StdDev Altitude")
).orderBy("prediction")
summary_stats_gmm.show()

summary_stats_kmeans = predictions_kmeans_test.groupBy("prediction").agg(
    func.min("Altitude").alias("Min Altitude"),
    func.max("Altitude").alias("Max Altitude"),
    func.mean("Altitude").alias("Mean Altitude"),
    func.stddev("Altitude").alias("StdDev Altitude")
).orderBy("prediction")
summary_stats_kmeans.show()

predictions_kmeans_pd = predictions_kmeans_test.select("Latitude", "Longitude", "prediction").toPandas()
predictions_gmm_pd = predictions_gmm_test.select("Latitude", "Longitude", "prediction").toPandas()

# Plot Kmeans
alpha = {0: 0.7, 1: 1, 2: 0.5}

for cluster_id in predictions_kmeans_pd['prediction'].unique():
    subset = predictions_kmeans_pd[predictions_kmeans_pd['prediction'] == cluster_id]
    plt.scatter(subset['Longitude'], subset['Latitude'], label=f'Cluster {cluster_id}', alpha=alpha.get(cluster_id, 1))

plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.title("Kmeans Clustering Based on Altitude")
plt.legend(title='Cluster ID')
plt.show()

# plot GMM
alpha = {0: 0.2, 1: 0.6, 2: 0.8}
for cluster_id in predictions_gmm_pd['prediction'].unique():
    subset = predictions_gmm_pd[predictions_gmm_pd['prediction'] == cluster_id]
    plt.scatter(subset['Longitude'], subset['Latitude'], label=f'Cluster {cluster_id}',alpha=alpha.get(cluster_id, 1))

plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.title("GMM Clustering Based on Altitude")
plt.legend(title='Cluster ID')
plt.show()

# use two features

gmm = GaussianMixture(k=3, tol=0.0001, seed=10)
kmeans = KMeans(k=3, tol=0.0001, seed=10)


vec_assembler3 = VectorAssembler(inputCols=["Latitude", "Longitude"], outputCol="features")

pipeline_gmm = Pipeline(stages=[vec_assembler3, gmm])
pipeline_kmeans = Pipeline(stages=[vec_assembler3, kmeans])

model_kmeans = pipeline_kmeans.fit(train_data)
model_gmm = pipeline_gmm.fit(train_data)

predictions_kmeans_train = model_kmeans.transform(train_data)
predictions_kmeans_test = model_kmeans.transform(test_data)

predictions_gmm_train = model_gmm.transform(train_data)
predictions_gmm_test = model_gmm.transform(test_data)

evaluator = ClusteringEvaluator()

# Evaluate K-Means
silhouette_kmeans_train = evaluator.evaluate(predictions_kmeans_train)
silhouette_kmeans_test = evaluator.evaluate(predictions_kmeans_test)

# Evaluate GMM
silhouette_gmm_train = evaluator.evaluate(predictions_gmm_train)
silhouette_gmm_test = evaluator.evaluate(predictions_gmm_test)

print(f"K-Means Silhouette Score (Train): {silhouette_kmeans_train}, (Test): {silhouette_kmeans_test}")
print(f"GMM Silhouette Score (Train): {silhouette_gmm_train}, (Test): {silhouette_gmm_test}")

predictions_kmeans_pd = predictions_kmeans_test.select("Latitude", "Longitude", "prediction").toPandas()
predictions_gmm_pd = predictions_gmm_test.select("Latitude", "Longitude", "prediction").toPandas()
for cluster_id in predictions_kmeans_pd['prediction'].unique():
    subset = predictions_kmeans_pd[predictions_kmeans_pd['prediction'] == cluster_id]
    plt.scatter(subset['Longitude'], subset['Latitude'], label=f'Cluster {cluster_id}')

plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.title("Kmeans Clustering Based on Latitude and Longitude")
plt.legend(title='Cluster ID')
plt.show()

for cluster_id in predictions_gmm_pd['prediction'].unique():
    subset = predictions_gmm_pd[predictions_gmm_pd['prediction'] == cluster_id]
    plt.scatter(subset['Longitude'], subset['Latitude'], label=f'Cluster {cluster_id}')

plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.title("GMM Clustering Based on Latitude and Longitude")
plt.legend(title='Cluster ID')
plt.show()

# appendix
# silhouette scores for choosing K, I will run it when choosing new features
silhouette_scores = []
evaluator = ClusteringEvaluator()

for k in range(2, 10):
    kmeans = KMeans(k=k, tol=0.0001, seed=10)
    model_kmeans = kmeans.fit(vec_assembler3.transform(train_data))
    predictions_kmeans = model_kmeans.transform(vec_assembler3.transform(train_data))
    silhouette = evaluator.evaluate(predictions_kmeans)
    silhouette_scores.append(silhouette)

plt.figure(figsize=(8, 6))
plt.plot(range(2, 10), silhouette_scores, marker='o')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Silhouette Score')
plt.title('Optimal K for Kmeans')
plt.show()

silhouette_scores_gmm = []


for k in range(2, 10):
    gmm = GaussianMixture(k=k, tol=0.0001, seed=10)
    model_gmm = gmm.fit(vec_assembler3.transform(train_data))
    predictions_gmm = model_gmm.transform(vec_assembler3.transform(train_data))
    silhouette = evaluator.evaluate(predictions_gmm)
    silhouette_scores_gmm.append(silhouette)

plt.figure(figsize=(8, 6))
plt.plot(range(2, 10), silhouette_scores_gmm, marker='o')
plt.xlabel('Number of Components (K)')
plt.ylabel('Silhouette Score')
plt.title('Optimal K for GMM')
plt.show()

# classification model using LogisticRegression and RandomForest
# to classify the type of airport

feature_columns = ["Latitude", "Longitude", "Timezone", "Altitude"]
vec_assembler4 = VectorAssembler(inputCols=feature_columns, outputCol="features")

lr = LogisticRegression(featuresCol="features", labelCol="label")
rf = RandomForestClassifier(featuresCol="features", labelCol="label")

pipeline_lr = Pipeline(stages=[vec_assembler4, lr])
pipeline_rf = Pipeline(stages=[vec_assembler4, rf])

model_lr = pipeline_lr.fit(train_data)
model_rf = pipeline_rf.fit(train_data)

predictions_lr = model_lr.transform(test_data)
predictions_rf = model_rf.transform(test_data)


evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
accuracy_lr = evaluator.evaluate(predictions_lr)
accuracy_rf = evaluator.evaluate(predictions_rf)

print(f"accuracy: {accuracy_lr}")
print(f"accuracy: {accuracy_rf}")

